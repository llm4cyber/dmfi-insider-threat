# Dual-Modality Insider Threat Detection (DMFI) 

This repository contains the source code and instructions for reproducing the results of our paper submitted to [a top-tier data mining conference in 2025].

> Note: For anonymity, author and affiliation information have been removed.

## Contents
- Preprocessing scripts for CERT dataset
- LoRA fine-tuning pipeline using LLaMA-Factory
- Semantic/Behavioral prompt generation
- Evaluation code and baseline comparisons

The full architecture is shown in the PDF below:

<img src="./assets/Structrue.png" alt="main" style="zoom: 33%;" />

## Preprocessing Pipeline

<img src="./assets/Compress_Sequence.png" alt="main" style="zoom: 33%;" />

Illustrative example of behavior sequence compression. 
The left table organizes raw user actions using the 4W schema (When, Where, What, Which).
On the right, we compare the original verbose sequence with a compressed version generated by our 4W-guided abstraction strategy.
While the original form enumerates each atomic behavior separately, the compressed version merges related actions into concise natural language.
This reduces token length (from 49 to 31 in this case) while retaining key behavioral semantics.

## 🗂️ Folder Structure

```
dmfi/
├── assets/
├── deployment/
│   └── README_DeepSeek_Finetuning.md
├── preprocess/
│   ├── features/
│   │   ├── behavior_sequence/
│   │   ├── semantic_content/
│   │   └── alpaca/
│   └── output/
│       ├── log_split/
│       └── log_merged/
├── step1_log_split.py
├── step2_log_merge.py
├── step3_log_labeling.py
├── step4_1_sequence_feature_engineering.py
├── step4_2_semantic_feature_engineering.py
├── step5_alpaca_feature_engineering.py
├── utils_for_feature.py
└── config.yaml
```

## 🤖 LLM Finetuning 

### ✅ Environment

- **Hardware**:
  - 4× NVIDIA L20 GPUs
  - 512 GB RAM
  - Intel Xeon Gold 6430
- **Software**:
  - Ubuntu 20.04 LTS
  - Python 3.8.10
  - CUDA 12.4
  - LLaMA-Factory 0.9.3.dev0

### 🔽 Model Download

```bash
git lfs install
git clone https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
```

Or visit: https://huggingface.co/deepseek-ai

### 🚀 Training Setup

```bash
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
conda create -n llama_factory python=3.8
conda activate llama_factory
cd LLaMA-Factory
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -e .[metrics]
llamafactory-cli version
```

Then follow the instructions in `deployment/README_DeepSeek_Finetuning.md`.

---

## 🔍 Inference Format

```json
{
  "instruction": "Please analyze the following behavior sequence...",
  "input": "During working hours at Self_PC, logon, then access multiple websites (megaclick.com, linkedin.com)...",
  "output": "Anomaly Score = 1.00, Prediction = “Abnormal”"
}
```

---
